# -*- coding: utf-8 -*-
"""AVA_Downloader.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k20lxfvSrb8sDqAmO4CeFeooOa8DvGci
"""
import argparse
import glob
import json
import os
import shutil
import subprocess
import uuid
from collections import OrderedDict

from joblib import delayed
from joblib import Parallel
import pandas as pd

def download_clip(video_identifier, output_filename,
                   tmp_dir='/content/videos',
                  num_attempts=5,
                  url_base='https://www.youtube.com/watch?v='):
    """Download a video from youtube if exists and is not blocked.
    arguments:
    ---------
    video_identifier: str
        Unique YouTube video identifier (11 characters)
    output_filename: str
        File path where the video will be stored.
    start_time: float
        Indicates the begining time in seconds from where the video
        will be trimmed.
    end_time: float
        Indicates the ending time in seconds of the trimmed video.
    """
    # Defensive argument checking.
    assert isinstance(video_identifier, str), 'video_identifier must be string'
    assert isinstance(output_filename, str), 'output_filename must be string'
    assert len(video_identifier) == 11, 'video_identifier must have length 11'

    status = False
    # Construct command line for getting the direct video link.
    tmp_filename = os.path.join(tmp_dir,output_filename)
    status =  os.path.exists(tmp_filename)
    if status:
      print("Video already exists... Skipping.")
      return status, 'Downloaded'

    command = ['youtube-dl',
               '--quiet', '--no-warnings',
               '-f', 'mp4',
               '-o', '"{}"'.format(tmp_filename) ,
               '"%s"' % (url_base + video_identifier)]
    command = ' '.join(command)
    attempts = 0
    print (command)
    while True:
        try:
            print("Downloading video: {}".format(video_id))
            output = subprocess.check_output(command, shell=True,
                                             stderr=subprocess.STDOUT)
        except subprocess.CalledProcessError as err:
            attempts += 1
            if attempts == num_attempts:
                return status, err.output
        else:
            break

    tmp_filename = glob.glob('%s*' % tmp_filename.split('.')[0])[0]
   
    # Check if the video was successfully saved.
    status = os.path.exists(tmp_filename)
   # os.remove(tmp_filename)
    return status, 'Downloaded'

def download_clip_wrapper(video_id):
    """Wrapper for parallel processing purposes."""
    output_filename = "{}.mp4".format(video_id)
    print("Downloading video: {}".format(video_id))
    downloaded, log = download_clip(video_id, output_filename)
    status = tuple([video_id, downloaded, log])
    return status

def main(input_csv,
         num_jobs=24,
         drop_duplicates=False):
    
    
    dataset = pd.read_csv(input_csv, header = None)
    dataset.columns = ['video_id','middle_frame_timestamp','person_box_x1','person_box_y1','person_box_x2','person_box_y2','action_id','person_id']
    # Reading and parsing Kinetics.
    video_list = dataset['video_id'].unique()
    # if os.path.isfile(drop_duplicates):
    #     print('Attempt to remove duplicates')
    #     old_dataset = parse_kinetics_annotations(drop_duplicates,
    #                                              ignore_is_cc=True)
    #     df = pd.concat([dataset, old_dataset], axis=0, ignore_index=True)
    #     df.drop_duplicates(inplace=True, keep=False)
    #     print(dataset.shape, old_dataset.shape)
    #     dataset = df
    #     print(dataset.shape)

    # Creates folders where videos will be saved later.
    #label_to_dir = create_video_folders(dataset, output_dir, tmp_dir)

    # Download all clips.
    if num_jobs == 1:
        status_lst = []
        for i, video_id in enumerate(video_list):
            status_lst.append(download_clip_wrapper(video_id))
    else:
        status_lst = Parallel(n_jobs=num_jobs)(delayed(download_clip_wrapper)(
            video_id) for i, video_id in enumerate(video_list))

    # Clean tmp dir.
    #shutil.rmtree(tmp_dir)

    # Save download report.
    with open('download_report.json', 'w') as fobj:
        fobj.write(json.dumps(status_lst))

if __name__ == '__main__':
    description = 'Helper script for downloading and trimming kinetics videos.'
    p = argparse.ArgumentParser(description=description)
    p.add_argument('input_csv', type=str,
                   help=('CSV file containing the following format: '
                         'YouTube Identifier'))
    p.add_argument('-n', '--num-jobs', type=int, default=24)
   
    main(**vars(p.parse_args()))

    